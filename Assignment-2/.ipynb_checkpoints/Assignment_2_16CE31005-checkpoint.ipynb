{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers,metrics\n",
    "import scipy\n",
    "from sklearn.metrics import make_scorer,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_file = open('hi-ud-train.conllu','r')\n",
    "test_file = open('hi-ud-test.conllu','r')\n",
    "\n",
    "def preprocess(file,file_type):\n",
    "    corpus = []\n",
    "    sent = []\n",
    "    for line in file:\n",
    "        if file_type == 'tr':\n",
    "            if 'POS_TAG' in line:\n",
    "                continue\n",
    "            elif line == ',,\\n':\n",
    "                corpus.append(sent)\n",
    "                sent = []            \n",
    "            else:\n",
    "                tup = tuple(line[:-1].split(','))\n",
    "                sent.append(tup)\n",
    "        else:\n",
    "            if 'TAG' in line:\n",
    "                continue\n",
    "            elif line.split('\t')[2] =='\\n':\n",
    "                corpus.append(sent)\n",
    "                sent = []            \n",
    "            else:\n",
    "                tup = tuple(line.split())\n",
    "                sent.append(tup)\n",
    "    return corpus\n",
    "\n",
    "train = preprocess(train_corpus_file,'tr')\n",
    "test = preprocess(test_file,'te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit()        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][1]\n",
    "        postag1 = sent[i-1][2]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][1]\n",
    "        postag1 = sent[i+1][2]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [postag for num, token, postag in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [postag for num, token, postag in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above done feature extraction, I used word shape, word suffix, word identity and also some information about the nearby words as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'yaha',\n",
       " 'word[-3:]': 'aha',\n",
       " 'word[-2:]': 'ha',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': 'esiya',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train]\n",
    "y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "X_test = [sent2features(s) for s in test]\n",
    "y_test = [sent2labels(s) for s in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.005, c2=0.0267, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=150,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The following values of c1,c2 are obtained from hyperparameter optimization for 150 iterations\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.005,\n",
    "    c2=0.0267,\n",
    "    max_iterations=150,\n",
    "    all_possible_transitions=True\n",
    "    \n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8375695028148106\n",
      "Train Accuracy - \n",
      "0.9993419320873914\n",
      "Test Accuracy - \n",
      "0.8407202216066482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaswanth/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jaswanth/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "y_pred = crf.predict(X_test)\n",
    "y_train_pred = crf.predict(X_train)\n",
    "print(metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels))\n",
    "print('Train Accuracy - ')\n",
    "print(metrics.flat_accuracy_score(y_train, y_train_pred))\n",
    "print('Test Accuracy - ')\n",
    "print(metrics.flat_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "VERB   -> AUX    4.465070\n",
      "PROPN  -> PROPN  2.738170\n",
      "AUX    -> AUX    2.661140\n",
      "PRON   -> ADP    2.628760\n",
      "ADJ    -> NOUN   2.579719\n",
      "PROPN  -> ADP    2.523272\n",
      "AUX    -> SCONJ  2.225268\n",
      "NOUN   -> ADP    2.135462\n",
      "NUM    -> NOUN   2.082605\n",
      "DET    -> NOUN   1.979730\n",
      "\n",
      "\n",
      "Top unlikely transitions:\n",
      "AUX    -> ADJ    -1.552327\n",
      "PROPN  -> PART   -1.603829\n",
      "DET    -> CCONJ  -1.641650\n",
      "PROPN  -> DET    -1.656438\n",
      "NUM    -> PRON   -1.766365\n",
      "PROPN  -> AUX    -1.950686\n",
      "CCONJ  -> AUX    -1.973740\n",
      "ADJ    -> ADP    -2.226438\n",
      "ADJ    -> PRON   -2.299370\n",
      "DET    -> ADP    -2.824333\n"
     ]
    }
   ],
   "source": [
    "#Top 10 most common and least common transition features along with transition weights\n",
    "def print_transitions(features):\n",
    "    for (from_label, to_label), wgt in features:\n",
    "        print(\"%-6s -> %-6s %0.6f\" % (from_label, to_label, wgt))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(10))\n",
    "\n",
    "print('\\n')\n",
    "print(\"Top unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           X      0.000     0.000     0.000         0\n",
      "        PART      0.968     0.909     0.937        33\n",
      "       CCONJ      1.000     1.000     1.000        25\n",
      "       SCONJ      0.750     1.000     0.857         3\n",
      "         ADJ      0.667     0.766     0.713        94\n",
      "         ADP      0.946     0.980     0.963       303\n",
      "         ADV      0.600     0.429     0.500        21\n",
      "        VERB      0.859     0.798     0.827        99\n",
      "         DET      0.795     0.861     0.827        36\n",
      "       COMMA      0.000     0.000     0.000         0\n",
      "        NOUN      0.767     0.864     0.813       324\n",
      "        PRON      0.794     0.831     0.812        65\n",
      "       PROPN      0.648     0.486     0.556       144\n",
      "         NUM      0.920     0.920     0.920        25\n",
      "       PUNCT      1.000     0.828     0.906       134\n",
      "         AUX      0.935     0.942     0.939       138\n",
      "\n",
      "   micro avg      0.841     0.841     0.841      1444\n",
      "   macro avg      0.728     0.726     0.723      1444\n",
      "weighted avg      0.841     0.841     0.838      1444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaswanth/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jaswanth/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#precison, recall and f1-score per unique POS tag\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0]))\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
